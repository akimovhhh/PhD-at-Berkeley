{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imorting libraries \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import math\n",
    "import cufflinks as cf\n",
    "import plotly.figure_factory as ff\n",
    "import scipy\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from datetime import timedelta\n",
    "from subprocess import check_output\n",
    "import matplotlib as plt\n",
    "from pathlib import Path\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "cf.go_offline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_dict = pd.read_csv(\"/Users/akimovh/Library/CloudStorage/GoogleDrive-akimovhresearch@gmail.com/My Drive/predatory pricing/data/dict/L_CITY_MARKET_ID.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HI market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert base path to Path object for better path handling\n",
    "base_path = Path(\"/Users/akimovh/Library/CloudStorage/GoogleDrive-akimovhresearch@gmail.com/My Drive/predatory pricing/data/DB1B\")\n",
    "    \n",
    "# Pre-allocate list for DataFrames\n",
    "all_tickets_HI = []\n",
    "all_tickets_HA = []\n",
    "\n",
    "for year in range(2014, 2025):\n",
    "      for q in range(1, 5):\n",
    "            # Skip 2024 Q4\n",
    "            if year == 2024 and q == 4:\n",
    "                 continue\n",
    "            # Define file paths\n",
    "            ticket_file = base_path / f\"Ticket/{year}_{q}.csv\"\n",
    "            market_file = base_path / f\"Market/Origin_and_Destination_Survey_DB1BMarket_{year}_{q}.csv\"\n",
    "\n",
    "            market_cols = ['ItinID', 'TkCarrier', 'OpCarrier', 'MktCoupons', \n",
    "                         'OriginCityMarketID', 'DestCityMarketID', 'OriginCountry',\n",
    "                        'OriginState', 'DestCountry', 'DestState']\n",
    "            \n",
    "            market = pd.read_csv(market_file, usecols=market_cols)\n",
    "            mask_HI = (\n",
    "                        (market['MktCoupons'] == 1) &\n",
    "                        ((market['OriginState'] == 'HI') or (market['DestState'] == 'HI')) \n",
    "                      )\n",
    "            \n",
    "            mask_HA = (\n",
    "                        (market['MktCoupons'] == 1) &\n",
    "                        (market['TkCarrier'] == 'HA') \n",
    "                      )\n",
    "            market_HI = market[mask_HI]\n",
    "            market_HA = market[mask_HA]\n",
    "\n",
    "\n",
    "            Itin_ID_HI = market_HI.ItinID.unique()\n",
    "            Itin_ID_HI = market_HA.ItinID.unique()\n",
    "            \n",
    "\n",
    "            \n",
    "            # Read ticket data with only necessary columns\n",
    "            ticket_cols = ['ItinID', 'Coupons', 'RoundTrip', 'DollarCred', 'Year',\n",
    "                           'Quarter', 'ItinFare', 'BulkFare', 'Distance', 'DistanceGroup',\n",
    "                           'Passengers', 'OnLine']\n",
    "            \n",
    "\n",
    "            ticket = pd.read_csv(ticket_file, usecols=ticket_cols)\n",
    "            mask_HI = (\n",
    "                        (ticket['ItinID'].isin(Itin_ID_HI)) &\n",
    "                        (ticket['OnLine'] == 1)\n",
    "                      )\n",
    "            \n",
    "            mask_HA = (\n",
    "                        (ticket['ItinID'].isin(Itin_ID_HA)) &\n",
    "                        (ticket['OnLine'] == 1)\n",
    "                      )\n",
    "            ticket_HI = ticket[mask_HI]\n",
    "            ticket_HA = ticket[mask_HA]\n",
    "\n",
    "            # Add city names\n",
    "\n",
    "            market_HI = pd.merge(market_HI, city_dict,  left_on = 'OriginCityMarketID', right_on = 'Code', how = 'left')\n",
    "            ticket_HI = pd.merge(market_HI, city_dict,  left_on = 'DestCityMarketID', right_on = 'Code', how = 'left')\n",
    "            ticket_HA = pd.merge(ticket_HA, city_dict,  left_on = 'OriginCityMarketID', right_on = 'Code', how = 'left')\n",
    "            ticket_HA = pd.merge(ticket_HA, city_dict,  left_on = 'DestCityMarketID', right_on = 'Code', how = 'left')\n",
    "\n",
    "            \n",
    "          # Create msa_pair using vectorized operations\n",
    "\n",
    "            market_HI['city_pair_non_direct'] = market_HI.apply(\n",
    "                lambda row: str(tuple(sorted([row['Description_x'], \n",
    "                                           row['Description_y']]))), \n",
    "                axis=1\n",
    "            )\n",
    "            market_HI['state_pair_non_direct'] = market_HI.apply(\n",
    "                lambda row: str(tuple(sorted([row['OriginState'], \n",
    "                                           row['DestState']]))), \n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            market_HI['city_pair_direct'] = market_HI.apply(\n",
    "                lambda row: str(tuple(([row['Description_x'], \n",
    "                                           row['Description_y']]))), \n",
    "                axis=1\n",
    "            )\n",
    "            market_HI['state_pair_direct'] = market_HI.apply(\n",
    "                lambda row: str(tuple(([row['OriginState'], \n",
    "                                           row['DestState']]))), \n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            market_HA['city_pair_non_direct'] = market_HA.apply(\n",
    "                lambda row: str(tuple(sorted([row['Description_x'], \n",
    "                                           row['Description_y']]))), \n",
    "                axis=1\n",
    "            )\n",
    "            market_HA['state_pair_non_direct'] = market_HA.apply(\n",
    "                lambda row: str(tuple(sorted([row['OriginState'], \n",
    "                                           row['DestState']]))), \n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            market_HA['city_pair_direct'] = market_HA.apply(\n",
    "                lambda row: str(tuple(([row['Description_x'], \n",
    "                                           row['Description_y']]))), \n",
    "                axis=1\n",
    "            )\n",
    "            market_HA['state_pair_direct'] = market_HA.apply(\n",
    "                lambda row: str(tuple(([row['OriginState'], \n",
    "                                           row['DestState']]))), \n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            # Select final columns and drop duplicates\n",
    "            market_HI = market_HI[['ItinID', 'TkCarrier', 'city_pair', 'OpCarrier', 'state_pair']].drop_duplicates()\n",
    "            market_HA = market_HA[['ItinID', 'TkCarrier', 'city_pair', 'OpCarrier', 'state_pair']].drop_duplicates()\n",
    "\n",
    "            \n",
    "            # # Merge and append to results\n",
    "            merged_HI = pd.merge(market_HI, ticket_HI, on='ItinID')\n",
    "            merged_HA = pd.merge(merged_HA, ticket_HA, on='ItinID')\n",
    "\n",
    "            all_tickets_HI.append(merged_HI)\n",
    "            all_tickets_HA.append(merged_HA)\n",
    "            \n",
    "df_HI = pd.concat(all_tickets_HI)\n",
    "df_HA = pd.concat(all_tickets_HA)\n",
    "df_HI['date'] = pd.to_datetime(df_HI['Year'].astype(str) + '-' + ((df_HI['Quarter'] - 1) * 3 + 1).astype(str) + '-01')\n",
    "df_HA['date'] = pd.to_datetime(df_HA['Year'].astype(str) + '-' + ((df_HA['Quarter'] - 1) * 3 + 1).astype(str) + '-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    tickets['state_pair'] == \"('HI', 'HI')\",\n",
    "    tickets['country_pair'] == \"('US', 'US')\",\n",
    "]\n",
    "choices = ['Interstate', 'Other domestic']\n",
    "\n",
    "tickets['flight_type'] = np.select(conditions, choices, default='Bad data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = tickets.groupby(by = ['date', 'flight_type'], as_index = False).Passengers.sum()\n",
    "plot_data['Passengers'] = plot_data['Passengers']*10\n",
    "fig = px.line(plot_data, x=\"date\", y=\"Passengers\", color='flight_type')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = tickets.groupby(by = ['date', 'flight_type'], as_index = False).Passengers.sum()\n",
    "plot_data['total_Passengers'] = plot_data.groupby(by = ['date'], as_index = False).Passengers.transform('sum')\n",
    "plot_data['Share'] = plot_data['Passengers']/plot_data['total_Passengers']*100\n",
    "fig = px.line(plot_data, x=\"date\", y=\"Share\", color='flight_type')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interisland flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_ha = tickets[tickets['state_pair'] == \"('HI', 'HI')\"].query(\"TkCarrier in ['HA', 'WN', 'WP']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = inner_ha.groupby(by = ['date', 'TkCarrier'], as_index = False).Passengers.sum()\n",
    "plot_data['Passengers'] = plot_data['Passengers']*10\n",
    "fig = px.line(plot_data, x=\"date\", y=\"Passengers\", color='TkCarrier')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = inner_ha.groupby(by = ['date', 'TkCarrier'], as_index = False).Passengers.sum()\n",
    "plot_data['Passengers'] = plot_data['Passengers']*10\n",
    "plot_data['total_Passengers'] = plot_data.groupby(by = ['date'], as_index = False).Passengers.transform('sum')\n",
    "plot_data['Share'] = plot_data['Passengers']/plot_data['total_Passengers']*100\n",
    "fig = px.line(plot_data, x=\"date\", y=\"Share\", color='TkCarrier')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_ha_agg = inner_ha.groupby(by = ['TkCarrier', 'date', 'city_pair'], as_index = False).Passengers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_ha_fares = inner_ha.query('ItinFare>20')\n",
    "inner_ha_fares['passengers_per_quarter'] = inner_ha_fares.groupby(by = ['TkCarrier', 'city_pair', 'date']).Passengers.transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_ha_fares = inner_ha_fares.sort_values(by = 'ItinFare')\n",
    "inner_ha_fares['passengers_per_quarter_cum'] = inner_ha_fares.groupby(by = ['TkCarrier', 'city_pair', 'date']).Passengers.transform('cumsum')\n",
    "mask = (\n",
    "        (inner_ha_fares['passengers_per_quarter_cum']/inner_ha_fares['passengers_per_quarter']>0.01) & \n",
    "        (inner_ha_fares['passengers_per_quarter_cum']/inner_ha_fares['passengers_per_quarter']<0.99) \n",
    "                   )\n",
    "inner_ha_fares = inner_ha_fares[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_ha_fares['Revenue'] = inner_ha_fares['Passengers']*inner_ha_fares['ItinFare']\n",
    "inner_ha_fares = inner_ha_fares.groupby(by = ['TkCarrier', 'date', 'city_pair'], as_index = False).agg(Passengers = ('Passengers', 'sum'),\n",
    "                                                                                                       Revenue = ('Revenue', 'sum'))\n",
    "inner_ha_fares_agg = inner_ha_fares.groupby(by = ['TkCarrier', 'date'], as_index = False).agg(Passengers = ('Passengers', 'sum'),\n",
    "                                                                                                       Revenue = ('Revenue', 'sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_ha_fares['Price'] = inner_ha_fares.Revenue/ inner_ha_fares.Passengers\n",
    "inner_ha_fares_agg['Price'] = inner_ha_fares_agg.Revenue/ inner_ha_fares_agg.Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = inner_ha_fares_agg.groupby(by = ['date', 'TkCarrier'], as_index = False).Price.sum()\n",
    "fig = px.line(plot_data, x=\"date\", y=\"Price\", color='TkCarrier')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    tickets['state_pair'] == \"('HI', 'HI')\",\n",
    "    tickets['country_pair'] == \"('US', 'US')\",\n",
    "]\n",
    "choices = ['Interstate', 'Other domestic']\n",
    "\n",
    "tickets['flight_type'] = np.select(conditions, choices, default='Bad data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets.to_csv(\"/Users/akimovh/My documents/projects/predatory pricing/data/temporal/HI_flights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hawaiian airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert base path to Path object for better path handling\n",
    "base_path = Path(\"/Users/akimovh/Library/CloudStorage/GoogleDrive-akimovhresearch@gmail.com/My Drive/predatory pricing/data/DB1B\") \n",
    "   \n",
    "# Pre-allocate list for DataFrames\n",
    "all_tickets = []\n",
    "\n",
    "for year in range(2017, 2025):\n",
    "      for q in range(1, 5):\n",
    "            # Skip 2024 Q4\n",
    "            if year == 2024 and q == 4:\n",
    "                 continue\n",
    "            # Define file paths\n",
    "            ticket_file = base_path / f\"Ticket/{year}_{q}.csv\"\n",
    "            market_file = base_path / f\"Market/Origin_and_Destination_Survey_DB1BMarket_{year}_{q}.csv\"\n",
    "\n",
    "            market_cols = ['ItinID', 'TkCarrier', 'OpCarrier', 'MktCoupons', \n",
    "                         'OriginCityMarketID', 'DestCityMarketID', 'OriginCountry',\n",
    "                        'OriginState', 'DestCountry', 'DestState']\n",
    "            \n",
    "            tmp_1 = pd.read_csv(market_file, usecols=market_cols)\n",
    "            tmp_1 = tmp_1.query(\"MktCoupons == 1 and TkCarrier == 'HA'\")\n",
    "            Itin_ID = tmp_1.ItinID.unique()\n",
    "            \n",
    "\n",
    "            \n",
    "            # Read ticket data with only necessary columns\n",
    "            ticket_cols = ['ItinID', 'Coupons', 'RoundTrip', 'DollarCred', 'Year',\n",
    "                           'Quarter', 'ItinFare', 'BulkFare', 'Distance', 'DistanceGroup',\n",
    "                           'Passengers', 'OnLine']\n",
    "            \n",
    "            tmp = pd.read_csv(ticket_file, usecols=ticket_cols)\n",
    "            \n",
    "            # Apply filters using vectorized operations\n",
    "            mask = (tmp['ItinID'].isin(Itin_ID)) & (tmp['DollarCred'] == 1) & (tmp['BulkFare'] == 0) & (tmp['OnLine'] == 1)\n",
    "            tmp = tmp[mask]\n",
    "\n",
    "            # Add city names\n",
    "\n",
    "            tmp_1 = pd.merge(tmp_1, city_dict,  left_on = 'OriginCityMarketID', right_on = 'Code', how = 'left')\n",
    "            tmp_1 = pd.merge(tmp_1, city_dict,  left_on = 'DestCityMarketID', right_on = 'Code', how = 'left')\n",
    "\n",
    "            \n",
    "          # Create msa_pair using vectorized operations\n",
    "\n",
    "            tmp_1['city_pair'] = tmp_1.apply(\n",
    "                lambda row: str(tuple(sorted([row['Description_x'], \n",
    "                                           row['Description_y']]))), \n",
    "                axis=1\n",
    "            )\n",
    "            tmp_1['state_pair'] = tmp_1.apply(\n",
    "                lambda row: str(tuple(sorted([row['OriginState'], \n",
    "                                           row['DestState']]))), \n",
    "                axis=1\n",
    "            )\n",
    "            tmp_1['country_pair'] = tmp_1.apply(\n",
    "                lambda row: str(tuple(sorted([row['OriginCountry'], \n",
    "                                           row['DestCountry']]))), \n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            # Select final columns and drop duplicates\n",
    "            tmp_1 = tmp_1[['ItinID', 'TkCarrier', 'city_pair', 'OpCarrier', 'state_pair', 'country_pair']].drop_duplicates()\n",
    "\n",
    "            \n",
    "            # # Merge and append to results\n",
    "            merged = pd.merge(tmp_1, tmp, on='ItinID')\n",
    "            all_tickets.append(merged)\n",
    "            \n",
    "tickets = pd.concat(all_tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    tickets['state_pair'] == \"('HI', 'HI')\",\n",
    "    tickets['state_pair'].str.contains(\"'HI'\"),\n",
    "]\n",
    "choices = ['Interstate HI', 'Hi-Mainland']\n",
    "\n",
    "tickets['flight_type'] = np.select(conditions, choices, default='Other domestic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets['date'] = pd.to_datetime(tickets['Year'].astype(str) + '-' + ((tickets['Quarter'] - 1) * 3 + 1).astype(str) + '-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = tickets.query(\"flight_type in ['Interstate HI', 'Hi-Mainland']\").groupby(by = ['date', 'flight_type'], as_index = False).Passengers.sum()\n",
    "plot_data['Passengers'] = plot_data['Passengers']*10\n",
    "fig = px.line(plot_data, x=\"date\", y=\"Passengers\", color='flight_type')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = tickets.query(\"flight_type in ['Interstate HI', 'Hi-Mainland']\").groupby(by = ['date', 'flight_type'], as_index = False).Passengers.sum()\n",
    "plot_data['Passengers'] = plot_data['Passengers']*10\n",
    "plot_data['total_Passengers'] = plot_data.groupby(by = ['date'], as_index = False).Passengers.transform('sum')\n",
    "plot_data['Share'] = plot_data['Passengers']/plot_data['total_Passengers']*100\n",
    "fig = px.line(plot_data, x=\"date\", y=\"Share\", color =  'flight_type' )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = pd.DataFrame()\n",
    "for year in range(2017,2025):\n",
    "    costs = pd.concat([costs, pd.read_csv(f\"/Users/akimovh/My documents/projects/predatory pricing/data/cost_data/{year}.csv\")])\n",
    "costs = costs.query(\"UNIQUE_CARRIER == 'HA'\")\n",
    "costs = costs.query(\"REGION == 'D'\")\n",
    "costs['date'] = pd.to_datetime(costs['YEAR'].astype(str) + '-' + ((costs['QUARTER'] - 1) * 3 + 1).astype(str) + '-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = costs.sort_values(by = 'date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = costs[['date', \"INCOME_PRE_TAX\"]]\n",
    "plot_data[\"INCOME_PRE_TAX\"] = plot_data[\"INCOME_PRE_TAX\"]*1000\n",
    "fig = px.line(costs, x=\"date\", y=\"INCOME_PRE_TAX\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
